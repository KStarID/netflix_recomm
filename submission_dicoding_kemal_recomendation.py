# -*- coding: utf-8 -*-
"""Submission Dicoding Kemal_Recomendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/147wHDcLGC2meMmROF_9_SU2wF1qGLoZx

# Proyek Recomendation System: Netflix Movies
---


- **Nama:** Kemal Aziz
- **Email:** kemal.aziz03@gmail.com
- **ID Dicoding:** kstarid

## Import Semua Packages/Library yang Digunakan
"""

# Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

# Download NLTK resources
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('punkt_tab')

# Mengunggah kredensial Kaggle
from google.colab import files
files.upload()  # Unggah file kaggle.json yang Anda dapatkan dari akun Kaggle Anda

# Membuat direktori .kaggle dan memindahkan file kaggle.json
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Unduh dataset
!kaggle datasets download -d shivamb/netflix-shows

# Ekstrak file ZIP
!unzip netflix-shows.zip -d netflix-shows

# Membaca data
df = pd.read_csv('/content/netflix-shows/netflix_titles.csv', skipfooter=1, engine='python')
df.info()
df.describe()

"""# Data Exploration"""

df.head() # Menampilkan 5 data pertama

df.info() # Menampilkan informasi data

df.describe()

# Memeriksa nilai yang hilang
print("\n--- Nilai yang Hilang ---")
missing_values = df.isnull().sum()
missing_percent = (missing_values / len(df)) * 100
missing_df = pd.DataFrame({'Missing Values': missing_values, 'Percent': missing_percent})
print(missing_df)

# Visualisasi distribusi jenis konten
plt.figure(figsize=(10, 6))
content_counts = df['type'].value_counts()
plt.pie(content_counts, labels=content_counts.index, autopct='%1.1f%%', startangle=90, colors=['#ff9999','#66b3ff'])
plt.title('Distribusi Jenis Konten di Netflix')
plt.axis('equal')
plt.show()

# Visualisasi top 10 genre
plt.figure(figsize=(12, 6))
genre_data = df['listed_in'].str.split(', ').explode()
top_genres = genre_data.value_counts().head(10)
sns.barplot(x=top_genres.values, y=top_genres.index, palette='magma')
plt.title('10 Genre Terpopuler di Netflix')
plt.xlabel('Jumlah Konten')
plt.tight_layout()
plt.show()

"""# Pre-Processing"""

# Mengisi nilai yang hilang
df['director'].fillna('Unknown Director', inplace=True)
df['cast'].fillna('Unknown Cast', inplace=True)
df['country'].fillna('Unknown Country', inplace=True)
df['description'].fillna('No description available', inplace=True)
df['date_added'].fillna('Unknown', inplace=True)
df['rating'].fillna('Not Rated', inplace=True)

print("\nSetelah:")
print(df.isnull().sum())

def clean_text(text):
    # Mengubah ke lowercase
    text = text.lower()
    # Menghapus karakter khusus
    text = re.sub(r'[^\w\s]', '', text)
    # Menghapus angka
    text = re.sub(r'\d+', '', text)
    # Tokenisasi
    tokens = nltk.word_tokenize(text)
    # Menghapus stopwords
    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]
    # Stemming
    stemmer = PorterStemmer()
    tokens = [stemmer.stem(word) for word in tokens]
    # Menggabungkan kembali
    return ' '.join(tokens)

# Membuat kolom baru untuk content-based filtering
df['content_features'] = df['director'] + ' ' + df['cast'] + ' ' + df['listed_in'] + ' ' + df['description']

df['content_features_cleaned'] = df['content_features'].apply(clean_text) # Proses cleaning

df # Menampilkan data

# Membuat dataframe untuk simulasi rating
np.random.seed(42)
n_users = 1000
n_items = len(df)

# Membuat ID pengguna
user_ids = [f'user_{i}' for i in range(1, n_users + 1)]

# Membuat simulasi data rating
ratings_data = []
for user_id in user_ids:
    # Setiap pengguna memberikan rating untuk 20-50 item secara acak
    n_ratings = np.random.randint(20, 50)
    item_indices = np.random.choice(n_items, n_ratings, replace=False)

    for idx in item_indices:
        # Rating antara 1-5 dengan bias ke arah rating tinggi (lebih realistis)
        rating = np.random.choice([1, 2, 3, 4, 5], p=[0.05, 0.1, 0.2, 0.3, 0.35])
        ratings_data.append({
            'user_id': user_id,
            'item_id': df.iloc[idx]['show_id'],
            'title': df.iloc[idx]['title'],
            'rating': rating
        })

# Membuat dataframe ratings
ratings_df = pd.DataFrame(ratings_data)
print(f"Jumlah data rating yang dibuat: {len(ratings_df)}")
print(ratings_df.head())

# Menyimpan dataset yang sudah diproses
df.to_csv('netflix_processed.csv', index=False)
ratings_df.to_csv('netflix_ratings_simulated.csv', index=False)

"""# Content-Based Filtering"""

# Menggunakan TF-IDF Vectorizer untuk mengekstrak fitur dari teks
print("Mengekstrak fitur menggunakan TF-IDF...")
tfidf = TfidfVectorizer(max_features=5000)
tfidf_matrix = tfidf.fit_transform(df['content_features_cleaned'])
print(f"Dimensi matriks TF-IDF: {tfidf_matrix.shape}")

# Menghitung cosine similarity
print("Menghitung cosine similarity...")
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)
print(f"Dimensi matriks cosine similarity: {cosine_sim.shape}")

# Membuat mapping dari indeks ke judul dan sebaliknya
indices = pd.Series(df.index, index=df['title']).drop_duplicates()

# Fungsi untuk mendapatkan rekomendasi berdasarkan kesamaan konten
def get_content_based_recommendations(title, cosine_sim=cosine_sim, df=df, indices=indices, top_n=10):
    # Mendapatkan indeks dari judul
    try:
        idx = indices[title]
    except:
        return pd.DataFrame({'title': ['Title not found in the dataset']})

    # Mendapatkan skor kesamaan untuk semua konten dengan konten yang dipilih
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Mengurutkan konten berdasarkan skor kesamaan
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Mendapatkan top N konten yang paling mirip (tidak termasuk konten itu sendiri)
    sim_scores = sim_scores[1:top_n+1]

    # Mendapatkan indeks konten
    content_indices = [i[0] for i in sim_scores]

    # Mengembalikan dataframe dengan rekomendasi
    recommendations = df.iloc[content_indices][['title', 'type', 'listed_in', 'description']]
    recommendations['similarity_score'] = [i[1] for i in sim_scores]
    return recommendations

"""# Evaluation

# Uji Coba
"""

# Uji coba dengan dua judul film yang ada di dataset
title1 = 'Stranger Things'
title2 = 'Breaking Bad'

# Mendapatkan indeks film dari judul
try:
    movie_idx1 = df[df['title'] == title1].index[0]
    movie_idx2 = df[df['title'] == title2].index[0]

    print("***TESTCASE 1 - CONTENT-BASED FILTERING***")
    print(f"Karena Anda menyukai film/acara TV '{title1}', mungkin Anda juga menyukai:")

    # Mendapatkan skor kesamaan untuk film pertama
    scores = list(enumerate(cosine_sim[movie_idx1]))

    # Mengurutkan film berdasarkan skor kesamaan
    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)

    # Mengambil 10 film teratas (tidak termasuk film itu sendiri)
    sorted_scores = sorted_scores[1:11]

    # Menampilkan rekomendasi
    for i, score in enumerate(sorted_scores):
        idx = score[0]
        print(f"{i+1}. {df.iloc[idx]['title']} - {df.iloc[idx]['type']} - {df.iloc[idx]['listed_in']} (Skor Kesamaan: {score[1]:.4f})")

    print("\n***TESTCASE 2 - CONTENT-BASED FILTERING***")
    print(f"Karena Anda menyukai film/acara TV '{title2}', mungkin Anda juga menyukai:")

    # Mendapatkan skor kesamaan untuk film kedua
    scores2 = list(enumerate(cosine_sim[movie_idx2]))

    # Mengurutkan film berdasarkan skor kesamaan
    sorted_scores2 = sorted(scores2, key=lambda x: x[1], reverse=True)

    # Mengambil 10 film teratas (tidak termasuk film itu sendiri)
    sorted_scores2 = sorted_scores2[1:11]

    # Menampilkan rekomendasi
    for i, score in enumerate(sorted_scores2):
        idx = score[0]
        print(f"{i+1}. {df.iloc[idx]['title']} - {df.iloc[idx]['type']} - {df.iloc[idx]['listed_in']} (Skor Kesamaan: {score[1]:.4f})")

except IndexError:
    print(f"Film/acara TV '{title1}' atau '{title2}' tidak ditemukan dalam dataset.")
    # Jika judul tidak ditemukan, gunakan judul yang ada di dataset
    sample_titles = df['title'].sample(2, random_state=42).values
    print(f"Mencoba dengan judul yang tersedia: {sample_titles[0]} dan {sample_titles[1]}")

    # Mendapatkan indeks film dari judul
    movie_idx1 = df[df['title'] == sample_titles[0]].index[0]
    movie_idx2 = df[df['title'] == sample_titles[1]].index[0]